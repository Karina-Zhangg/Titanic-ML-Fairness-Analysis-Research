{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YBroUveHdu41",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef3778888a8185b64a323b133a8adcde",
     "grade": false,
     "grade_id": "cell-90d792391597de0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **Introduction**\n",
    "\n",
    "This project explores the Titanic dataset, focusing on understanding survival factors and evaluating fairness in predictive modeling. By analyzing passenger data, I aimed to answer the following questions:\n",
    "- What factors influenced survival on the Titanic?\n",
    "- How can machine learning models predict survival outcomes effectively?\n",
    "- Is the model fair across different demographic and socioeconomic groups?\n",
    "\n",
    "### **Goals of the Project**\n",
    "1. **Data Exploration and Preprocessing**:  \n",
    "   I began by cleaning and transforming the Titanic dataset to ensure it was ready for analysis. This involved handling missing values, encoding categorical variables, and scaling numerical features.\n",
    "\n",
    "2. **Predictive Modeling**:  \n",
    "   Using logistic regression, I built a classification model to predict survival based on passenger features such as age, gender, class, and fare.\n",
    "\n",
    "3. **Fairness Analysis**:  \n",
    "   I conducted a fairness evaluation to assess the model’s performance across sensitive groups (e.g., gender, age, socioeconomic class). This included computing metrics like demographic parity, equal opportunity, and equalized odds.\n",
    "\n",
    "4. **Real-World Implications**:  \n",
    "   This project demonstrates the practical application of data science in addressing fairness and bias in machine learning models. Ensuring equitable outcomes is critical, especially in high-stakes scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "### **Significance of the Project**\n",
    "\n",
    "This analysis showcases my ability to:\n",
    "- Work with real-world datasets to extract meaningful insights.\n",
    "- Build machine learning models with a focus on both performance and fairness.\n",
    "- Communicate findings effectively, aligning technical work with ethical considerations.\n",
    "\n",
    "This project reflects my commitment to applying data science in ways that are impactful, equitable, and insightful. Through this personal project, I’ve combined technical rigor with thoughtful analysis to address both predictive accuracy and fairness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploring Survival Factors in the Titanic Disaster**\n",
    "\n",
    "In this project, I analyze the famous Titanic dataset to investigate the factors influencing survival during one of the most well-known maritime tragedies in history. The objective is to uncover patterns and relationships between passenger demographics, ticket class, and survival rates through data exploration and statistical modeling.\n",
    "\n",
    "### Key Questions Addressed:\n",
    "1. How did socioeconomic status (ticket class) impact survival likelihood?\n",
    "2. Did age and gender play a significant role in survival outcomes?\n",
    "3. What additional insights can we derive about the passengers and their journeys?\n",
    "\n",
    "### Methods:\n",
    "- **Data Preprocessing**: Handling missing and inconsistent data.\n",
    "- **Exploratory Data Analysis (EDA)**: Identifying trends and anomalies.\n",
    "- **Predictive Modeling**: Using statistical and machine learning models to predict survival probabilities.\n",
    "\n",
    "### Personal Motivation:\n",
    "Understanding survival factors in critical events like the Titanic tragedy offers valuable insights into human behavior and societal norms during crises. This project also serves as a practical application of data science techniques, including preprocessing, visualization, and predictive modeling, to derive meaningful conclusions from real-world data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZfrPg4x30DDJ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7c09601444fbcee6d56e3e3065e1cb0",
     "grade": false,
     "grade_id": "cell-96ada4da5a0ad7f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Initialization and Imports ---\n",
    "# Importing essential libraries for data manipulation, analysis, and visualization.\n",
    "import numpy as np\n",
    "from numpy.random import default_rng  # For random number generation\n",
    "import pandas as pd                  # For data manipulation and analysis\n",
    "from scipy.optimize import minimize  # For optimization tasks\n",
    "import statsmodels.api as sm         # For statistical modeling\n",
    "\n",
    "# --- Plotting Libraries ---\n",
    "# These libraries are used for creating high-quality visualizations.\n",
    "import matplotlib\n",
    "# Render the figure directly in the notebook (magic command for inline display).\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Set a modern and visually appealing plotting style.\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns                # For advanced data visualization\n",
    "\n",
    "# --- Warnings ---\n",
    "# Ignore specific warnings for a cleaner output (use cautiously in production code).\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# --- Purpose ---\n",
    "# This cell sets up the environment with the necessary libraries and configurations\n",
    "# for data analysis and visualization. Run this cell to initialize the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Evb1ew8P1yp8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb14e4d27fbbaf39f3f6bdf1c41a2d3b",
     "grade": false,
     "grade_id": "cell-1379add19442788f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it.\n",
    "rng_seed = 42\n",
    "rng = default_rng(rng_seed)\n",
    "rngstate = np.random.RandomState(rng_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "B9tpbJze1yp9",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0a801d9a9088efbf0836db0e0c149a7",
     "grade": false,
     "grade_id": "cell-608b2701efa9f27f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## **Data Preprocessing**\n",
    "\n",
    "To kick off my analysis, I started by loading the Titanic dataset into a pandas DataFrame (`df_init`) and performing essential data cleaning. Preprocessing is a crucial step to ensure the dataset is accurate, consistent, and ready for analysis.\n",
    "\n",
    "### **My Approach**\n",
    "1. I loaded the dataset into a pandas DataFrame and took a close look at its structure to understand what I was working with.\n",
    "2. By inspecting the data, I identified missing values and potential inconsistencies that could affect the analysis.\n",
    "3. I cleaned the dataset by retaining only the relevant columns, handling missing values, and ensuring all features were in a usable format.\n",
    "\n",
    "This step is the foundation of any meaningful analysis, and I took care to ensure that the data was well-structured, reliable, and ready for exploration and modeling. I believe that investing time in preprocessing leads to better insights and more robust results in the later stages of the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "id": "Hl4s47-Y1yp-",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4aa28d6bc7053b55a4733452a3b726e",
     "grade": false,
     "grade_id": "cell-07068cc9e0a486b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init = pd.read_csv('titanic.csv')\n",
    "\n",
    "print(\"Shape: \", df_init.shape)\n",
    "df_init.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "op6wZeEjdu43",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6290c9f6c23c3491ccb33c0fc2cc7fc6",
     "grade": true,
     "grade_id": "cell-fdbb4abf71f1ad23",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## **Dataset Description and Analysis Objectives**\n",
    "\n",
    "### **Purpose**\n",
    "The Titanic dataset offers a rich source of information about passengers on the Titanic, including demographic details, socioeconomic attributes, and survival outcomes. My goal with this analysis is to uncover the factors that influenced survival and to leverage these insights to potentially build predictive models. This project allows me to explore real-world data and sharpen my data analysis and modeling skills.\n",
    "\n",
    "### **Sensitive Variables**\n",
    "As I analyzed the dataset, I identified several sensitive variables that could have a significant impact on survival:\n",
    "- **Sex**: Gender played a critical role, with women generally prioritized during the evacuation.\n",
    "- **Pclass**: Passenger class reflects socioeconomic status and likely influenced access to lifeboats.\n",
    "- **Name**: Names may reveal implicit biases related to cultural or social status.\n",
    "- **Age**: Age could influence survival, as younger children and certain age groups might have been given priority.\n",
    "\n",
    "### **Features**\n",
    "I retained the following features for analysis as they provide meaningful context about each passenger:\n",
    "- **SibSp**: The number of siblings or spouses aboard, indicating family connections.\n",
    "- **Parch**: The number of parents or children aboard, providing insights into family structure.\n",
    "- **Fare**: The ticket price, which indirectly ties to passenger wealth and class.\n",
    "- **Embarked**: The port of embarkation, offering geographic and possibly socioeconomic context.\n",
    "\n",
    "### **Target Variable**\n",
    "The primary variable of interest is **Survived**, which indicates whether a passenger survived (1) or perished (0). This serves as the output for my analysis and predictive modeling efforts.\n",
    "\n",
    "### **Latent Variables**\n",
    "While the dataset does not explicitly include the following variables, I recognize they likely influenced survival outcomes:\n",
    "- **Social Connections**: Passengers with family or friends aboard may have had higher survival rates.\n",
    "- **Health Conditions**: The physical fitness or underlying health of passengers could have impacted their ability to survive.\n",
    "- **Decision-Making During Evacuation**: Behavioral responses and situational awareness in the crisis likely played a significant role.\n",
    "\n",
    "### **Why This Matters**\n",
    "By carefully considering these variables, I am laying the groundwork for an in-depth exploration of survival patterns. This analysis will not only provide insights into historical events but also demonstrate my ability to handle complex datasets and extract meaningful patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "qc_gkr_q1yqA",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec5ee29afc7fb4fd1323947d05a8c28c",
     "grade": true,
     "grade_id": "cell-bab795b4d2e8f91a",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## **Understanding the Dataset**\n",
    "\n",
    "### **Data Source**\n",
    "The dataset, `titanic.csv`, compiles detailed passenger information from the Titanic's ill-fated voyage. It serves as an excellent resource for analyzing survival factors and building predictive models. The data is derived from various historical sources, including:\n",
    "\n",
    "- **Passenger Manifests**: Official lists documenting passenger names, ages, and ticket details.\n",
    "- **Survival Records**: Historical documents noting the survival status of each passenger.\n",
    "- **Personal Testimonies**: Survivor accounts providing additional context about the event.\n",
    "\n",
    "This dataset intrigued me because it combines historical significance with real-world data science challenges, offering a perfect opportunity to hone my analytical and modeling skills.\n",
    "\n",
    "### **Methodology**\n",
    "Although the `titanic.csv` dataset doesn’t explicitly document its methodology, I inferred that it was curated by combining and standardizing data from historical records. If I were collecting similar data myself, I would take the following steps:\n",
    "1. **Aggregate Historical Data**: Gather data from passenger manifests, survival records, and survivor testimonies.\n",
    "2. **Verify Accuracy**: Cross-reference the data with reliable sources to ensure authenticity and consistency.\n",
    "3. **Standardize Variables**: Create meaningful, consistent features such as age groups, family connections, and travel details to enhance analytical clarity.\n",
    "\n",
    "This structured approach would ensure that the data is accurate, reliable, and ready for in-depth analysis.\n",
    "\n",
    "### **Analysis of the Dataset**\n",
    "To uncover survival patterns, I focused on these key areas:\n",
    "- **Demographic Variables**: Exploring the influence of age, gender, and socioeconomic status (ticket class) on survival outcomes.\n",
    "- **Family Connections**: Investigating how having family aboard (siblings/spouses or parents/children) impacted survival rates.\n",
    "- **Travel Details**: Analyzing ticket fares and ports of embarkation to identify potential correlations with survival.\n",
    "\n",
    "### **Why This Dataset?**\n",
    "I chose this dataset because it combines historical significance with practical challenges in data science. By exploring survival factors, I can connect data insights with human behavior during crises while showcasing my ability to work with real-world datasets. This analysis demonstrates my ability to clean, preprocess, and derive actionable insights from data while maintaining a critical perspective on its limitations and methodology.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fHhY4dkx1yqB",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d2fa41b13970292eba36a24b196dcef",
     "grade": false,
     "grade_id": "cell-90670bb121b85bdc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Data Preprocessing**\n",
    "\n",
    "Preprocessing the dataset is a key step in ensuring the data is clean, relevant, and ready for meaningful analysis. My approach focused on retaining only the necessary columns, addressing missing values, and refining the dataset to ensure the highest quality for exploration and modeling.\n",
    "\n",
    "### **My Approach to Preprocessing**\n",
    "\n",
    "1. **Identifying Relevant Columns**:\n",
    "   I began by selecting the most relevant columns that align with my analysis goals. These included:\n",
    "   - **Sensitive Features**: `Sex`, `Pclass`, `Age`, and `Name`, which provide crucial insights into demographic and socioeconomic factors.\n",
    "   - **Target Variable**: `Survived`, representing the survival outcome I aim to predict and analyze.\n",
    "   - **Other Relevant Features**: `SibSp`, `Parch`, `Fare`, and `Embarked`, which offer additional context about family connections, ticket pricing, and boarding locations.\n",
    "\n",
    "   These columns were chosen to balance the dataset's complexity while maintaining its analytical richness.\n",
    "\n",
    "2. **Handling Missing Data**:\n",
    "   Missing values can distort the results, so I carefully inspected the dataset for `NaN` values:\n",
    "   - Rows with missing data in critical fields such as `Age` or `Embarked` were removed to prevent bias.\n",
    "   - By focusing on complete records, I ensured the dataset’s reliability for downstream analysis.\n",
    "\n",
    "3. **Filtering the Dataset**:\n",
    "   While I avoided applying strict filters like age ranges or socioeconomic groups to retain a broad exploratory scope, I:\n",
    "   - Removed any rows containing invalid or extreme outlier values (e.g., unusually high fares) that could skew the analysis.\n",
    "   - Ensured that the dataset was free from inconsistencies that might undermine the results.\n",
    "\n",
    "### **Why This Process Matters**\n",
    "Preprocessing is the foundation of any robust analysis. By cleaning and refining the dataset, I ensured that the data is well-structured and reliable, setting the stage for meaningful insights and predictive modeling. This meticulous approach demonstrates my ability to work systematically and maintain a high standard of data quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "id": "ixPrae1q1yqB",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f81c8bd80c42b8dbac3fcaed342129e1",
     "grade": true,
     "grade_id": "cell-c47d3306e95b25dc",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (712, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Retain Relevant Columns ---\n",
    "# Define the columns that are essential for the analysis, including:\n",
    "# - Target variable: 'Survived'\n",
    "# - Sensitive features: 'Pclass', 'Sex', 'Age'\n",
    "# - Additional relevant features: 'SibSp', 'Parch', 'Fare', 'Embarked'\n",
    "cols_retain = ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "\n",
    "# Create a new DataFrame with only the selected columns for focused analysis\n",
    "df_filtered = df_init[cols_retain]\n",
    "\n",
    "# --- Handle Missing Data ---\n",
    "# Remove rows with missing values to ensure data consistency and reliability\n",
    "df_cleaned = df_filtered.dropna()\n",
    "\n",
    "# --- Check DataFrame Shape ---\n",
    "# Print the shape of the cleaned dataset (rows, columns) to verify the result\n",
    "print(\"Shape: \", df_cleaned.shape)\n",
    "\n",
    "# --- Display a Preview of the Data ---\n",
    "# Display the first few rows of the cleaned dataset to confirm successful preprocessing\n",
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WGZVZX0E1yqD",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18184049dd3cda7b1f544dd8bf228627",
     "grade": false,
     "grade_id": "cell-7c9c7917b17b0ba7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Ensuring the Output Variable is Numeric**\n",
    "\n",
    "To build effective models and conduct meaningful analysis, it is essential to ensure that the target variable (`Survived`) is numeric. Non-numeric or missing values can lead to errors or inconsistencies during modeling, so this step involves:\n",
    "1. Converting the target variable to a numeric type using `pd.to_numeric`.\n",
    "2. Removing rows with invalid or missing values in the target column.\n",
    "\n",
    "This ensures that the target variable is clean, consistent, and ready for predictive modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "id": "0URetjeg1yqD",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ed87d971cf253ada3dc13faa1dfa937",
     "grade": true,
     "grade_id": "cell-60cfc6c1d96486cb",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after ensuring 'Survived' is numeric and dropping NaNs:  (712, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karina\\AppData\\Local\\Temp\\ipykernel_19748\\2903514963.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Survived'] = pd.to_numeric(df_cleaned['Survived'], errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Convert 'Survived' to Numeric ---\n",
    "# The 'Survived' column represents whether a passenger survived the Titanic disaster.\n",
    "# Ensuring this target variable is numeric is critical for analysis and modeling.\n",
    "df_cleaned['Survived'] = pd.to_numeric(df_cleaned['Survived'], errors='coerce')\n",
    "\n",
    "# --- Handle Missing Values in 'Survived' ---\n",
    "# After conversion, any non-numeric values or NaNs in the 'Survived' column\n",
    "# are dropped to maintain data integrity.\n",
    "df_cleaned = df_cleaned.dropna(subset=['Survived'])\n",
    "\n",
    "# --- Verify the Data ---\n",
    "# Print the updated shape of the dataset to confirm the changes.\n",
    "print(\"Shape after ensuring 'Survived' is numeric and dropping NaNs: \", df_cleaned.shape)\n",
    "\n",
    "# Display the first few entries in the 'Survived' column as a final check.\n",
    "df_cleaned['Survived'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "p4LpFSX-1yqF",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb030e90bfda8e48ab337fd9f49fe3ff",
     "grade": false,
     "grade_id": "cell-703cb5823587e7c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Data exploration\n",
    "Let us now explore the statistics of the data.  Your data contains a variable of interest, which is the output.  Our goal is to compare the analysis of these outputs with the outputs of a logistic regression model we will build ourselves.\n",
    "\n",
    "We will plot the distribution of the variable of interest according to the first sensitive feature (that you defined in question 1) to see how it differs across different subgroups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "r3N65O3H1yqF",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ed69f239caf65600f9f8cf76d8370ff",
     "grade": false,
     "grade_id": "cell-9a196a293ab8f23f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## **Exploring the Data**\n",
    "\n",
    "To gain initial insights into the dataset, I analyzed the distribution of the target variable (`Survived`) with respect to the first sensitive feature, `Sex`. Understanding how survival rates differ across subgroups (e.g., male and female passengers) provides valuable context for further analysis and model-building.\n",
    "\n",
    "### **Objective**\n",
    "- Investigate how survival outcomes vary across the `Sex` feature.\n",
    "- Visualize the distribution of the `Survived` variable for each subgroup to identify potential patterns or disparities.\n",
    "\n",
    "This exploration step is crucial for developing an intuitive understanding of the data and identifying relationships that can inform the logistic regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "id": "J33m1a271yqF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20cfdc829859f0aab1ddac8e8727f1c6",
     "grade": true,
     "grade_id": "cell-61ed970094d68f24",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df_1 (Male):  (453, 8)\n",
      "Shape of df_2 (Female):  (259, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    Survived  Pclass   Sex   Age  SibSp  Parch     Fare Embarked\n",
       " 0          0       3  male  22.0      1      0   7.2500        S\n",
       " 4          0       3  male  35.0      0      0   8.0500        S\n",
       " 6          0       1  male  54.0      0      0  51.8625        S\n",
       " 7          0       3  male   2.0      3      1  21.0750        S\n",
       " 12         0       3  male  20.0      0      0   8.0500        S,\n",
       "    Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       " 1         1       1  female  38.0      1      0  71.2833        C\n",
       " 2         1       3  female  26.0      0      0   7.9250        S\n",
       " 3         1       1  female  35.0      1      0  53.1000        S\n",
       " 8         1       3  female  27.0      0      2  11.1333        S\n",
       " 9         1       2  female  14.0      1      0  30.0708        C)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Sensitive feature: 'Sex', with subgroups 'male' and 'female'\n",
    "\n",
    "# Create dataframes for the subgroups\n",
    "df_1 = df_cleaned[df_cleaned['Sex'] == 'male']    # Subgroup 1: Male\n",
    "df_2 = df_cleaned[df_cleaned['Sex'] == 'female']  # Subgroup 2: Female\n",
    "\n",
    "# Display the shape of each subgroup dataframe\n",
    "print(\"Shape of df_1 (Male): \", df_1.shape)\n",
    "print(\"Shape of df_2 (Female): \", df_2.shape)\n",
    "\n",
    "df_1.head(), df_2.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "gdHtELIO1yqH",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d3a9feaa3a7e0c1d5ef7371029ab91f",
     "grade": false,
     "grade_id": "cell-c6bb1f208ede838b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Visualizing Survival Proportions Across Subgroups**\n",
    "\n",
    "To better understand the distribution of survival outcomes (`Survived`), I created histograms to visualize the proportions of individuals in each subgroup for the sensitive feature `Sex`. This visualization helps identify patterns and disparities across groups, providing deeper insights into survival factors.\n",
    "\n",
    "### **Approach**\n",
    "- I plotted the histograms with `Survived` on the x-axis, representing the target variable with possible values 0 (did not survive) and 1 (survived).\n",
    "- The y-axis represents the proportion of individuals in each subgroup who fall into each survival category.\n",
    "- For clarity and comparison:\n",
    "  - I used separate subplots to display male and female subgroups side by side.\n",
    "  - I ensured that the axis limits and scales are consistent across plots to make comparisons meaningful.\n",
    "- I added titles, axis labels, and a legend to make the visualizations intuitive and informative.\n",
    "\n",
    "This step allows me to explore differences in survival rates between genders and provides a strong foundation for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "id": "lwb8Lnjc1yqH",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "958d2d2a30a95cc6a8b844a436cc3242",
     "grade": true,
     "grade_id": "cell-a7dbf4cfa6cfa7e2",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Calculate Proportions for Each Subgroup ---\n",
    "# I calculated the proportions of survival outcomes for each subgroup (e.g., male and female)\n",
    "# to normalize the data and make it easier to compare across groups.\n",
    "proportions_1 = df_1['Survived'].value_counts(normalize=True).sort_index()  # For males\n",
    "proportions_2 = df_2['Survived'].value_counts(normalize=True).sort_index()  # For females\n",
    "\n",
    "# --- Create Bar Plots to Visualize Proportions ---\n",
    "# Using side-by-side bar plots to compare survival distributions for males and females.\n",
    "\n",
    "# Create subplots for male and female subgroups\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "\n",
    "# --- Subgroup 1: Male ---\n",
    "axes[0].bar(\n",
    "    proportions_1.index, \n",
    "    proportions_1.values, \n",
    "    color='blue', \n",
    "    alpha=0.7, \n",
    "    label='Male'\n",
    ")\n",
    "axes[0].set_title('Survival Distribution for Males', fontsize=14)\n",
    "axes[0].set_xlabel('Survived', fontsize=12)\n",
    "axes[0].set_ylabel('Proportion', fontsize=12)\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels(['0\\nDid Not Survive', '1\\nSurvived'])  # Add mini labels beneath the bars\n",
    "axes[0].legend()\n",
    "\n",
    "# --- Subgroup 2: Female ---\n",
    "axes[1].bar(\n",
    "    proportions_2.index, \n",
    "    proportions_2.values, \n",
    "    color='red', \n",
    "    alpha=0.7, \n",
    "    label='Female'\n",
    ")\n",
    "axes[1].set_title('Survival Distribution for Females', fontsize=14)\n",
    "axes[1].set_xlabel('Survived', fontsize=12)\n",
    "axes[1].set_xticks([0, 1])\n",
    "axes[1].set_xticklabels(['0\\nDid Not Survive', '1\\nSurvived'])  # Add mini labels beneath the bars\n",
    "axes[1].legend()\n",
    "\n",
    "# --- Ensure Consistent Y-Axis Limits ---\n",
    "# Aligning y-axis across both subplots for an accurate comparison.\n",
    "axes[0].set_ylim(0, max(proportions_1.max(), proportions_2.max()) + 0.1)\n",
    "\n",
    "# --- Final Adjustments ---\n",
    "plt.tight_layout()  # Adjust spacing for better visualization\n",
    "plt.show()          # Display the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "aZiLZ2Fy1yqI",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91cfd4394c3563f0731fd249dab49572",
     "grade": true,
     "grade_id": "cell-7d4251c235f7bba7",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## **Insights from Survival Distributions**\n",
    "\n",
    "### **1. Survival Distribution by Gender**\n",
    "The histograms provide a clear visualization of survival outcomes (`Survived`) across the two subgroups of the sensitive feature, `Sex`:\n",
    "\n",
    "- **Male Passengers**: \n",
    "  - The majority of male passengers did not survive, as indicated by the taller blue bar at `0` (non-survival).\n",
    "  - A significantly smaller proportion of males survived, reflected by the shorter blue bar at `1` (survival).\n",
    "\n",
    "- **Female Passengers**: \n",
    "  - In contrast, a much larger proportion of female passengers survived, shown by the taller red bar at `1`.\n",
    "  - The proportion of non-survival among females is much smaller, as represented by the shorter red bar at `0`.\n",
    "\n",
    "### **2. Key Observations**\n",
    "- **Correlation Between Survival and Gender**: \n",
    "  - For male passengers, the survival rate is significantly lower compared to the non-survival rate.\n",
    "  - For female passengers, the survival rate is substantially higher than the non-survival rate.\n",
    "  \n",
    "- **Historical Context**: \n",
    "  - The observed gender-based disparity in survival outcomes aligns with historical accounts of the Titanic disaster. Specifically, the \"women and children first\" protocol during evacuation likely contributed to the higher survival rate among females.\n",
    "\n",
    "### **Conclusion**\n",
    "These insights underscore the impact of the sensitive feature `Sex` on survival outcomes. This analysis not only highlights a clear pattern in the data but also provides an opportunity to explore further questions, such as whether other features (e.g., age or class) amplified or mitigated this disparity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ArFMSbSM1yqJ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc19fcce851511e3ad8295d52b18c821",
     "grade": false,
     "grade_id": "cell-894dd6f08c7bc1de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## **Analyzing the Second Sensitive Feature**\n",
    "\n",
    "To expand my analysis, I explored survival outcomes across another sensitive feature: `Pclass`, which represents a passenger's socioeconomic class (1st, 2nd, or 3rd). Socioeconomic class played a significant role in access to resources during the Titanic disaster, and analyzing its relationship to survival can provide deeper insights into disparities.\n",
    "\n",
    "### **Approach**\n",
    "Since `Pclass` has three subgroups (1st, 2nd, and 3rd class), I categorized them into two broader groups for simplicity:\n",
    "- **High Class (`df_a`)**: Passengers from 1st and 2nd class, who were more likely to have better accommodations and faster access to lifeboats.\n",
    "- **Low Class (`df_b`)**: Passengers from 3rd class, who faced greater challenges during the evacuation.\n",
    "\n",
    "By separating the dataset into these two categories, I can investigate survival proportions and compare the outcomes for passengers from different socioeconomic groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "id": "umvtfb-T1yqK",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a44100339999e3133784650482205ebd",
     "grade": true,
     "grade_id": "cell-d0aaf9a2a0b3fb55",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df_a (First Class):  (184, 8)\n",
      "Shape of df_b (Not First Class):  (528, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       " 1          1       1  female  38.0      1      0  71.2833        C\n",
       " 3          1       1  female  35.0      1      0  53.1000        S\n",
       " 6          0       1    male  54.0      0      0  51.8625        S\n",
       " 11         1       1  female  58.0      0      0  26.5500        S\n",
       " 23         1       1    male  28.0      0      0  35.5000        S,\n",
       "    Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       " 0         0       3    male  22.0      1      0   7.2500        S\n",
       " 2         1       3  female  26.0      0      0   7.9250        S\n",
       " 4         0       3    male  35.0      0      0   8.0500        S\n",
       " 7         0       3    male   2.0      3      1  21.0750        S\n",
       " 8         1       3  female  27.0      0      2  11.1333        S)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Second Sensitive Feature: Socioeconomic Class (`Pclass`) ---\n",
    "# I chose `Pclass` as the second sensitive feature to analyze how socioeconomic factors influenced survival.\n",
    "# `Pclass` has three categories: 1 (First Class), 2 (Second Class), and 3 (Third Class).\n",
    "# For simplicity, I divided the passengers into two groups:\n",
    "# - `df_a`: Passengers in First Class (higher socioeconomic status).\n",
    "# - `df_b`: Passengers in Second and Third Class (lower socioeconomic status).\n",
    "\n",
    "# --- Create DataFrames for Subgroups ---\n",
    "# Subgroup A: First Class passengers\n",
    "df_a = df_cleaned[df_cleaned['Pclass'] == 1]\n",
    "\n",
    "# Subgroup B: Not First Class (combining Second and Third Class passengers)\n",
    "df_b = df_cleaned[df_cleaned['Pclass'] != 1]\n",
    "\n",
    "# --- Verify the Sizes of the Subgroups ---\n",
    "# Display the number of rows and columns in each subgroup for validation\n",
    "print(\"Shape of df_a (First Class): \", df_a.shape)\n",
    "print(\"Shape of df_b (Not First Class): \", df_b.shape)\n",
    "\n",
    "# --- Display Sample Data ---\n",
    "# Show the first few rows of each subgroup to ensure proper categorization\n",
    "df_a.head(), df_b.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "g7-3kHSO1yqL",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "23d82963068d352b33f650774b14839d",
     "grade": false,
     "grade_id": "cell-ed4035e5b54cc333",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Visualizing Survival Proportions by Socioeconomic Class**\n",
    "\n",
    "To explore the impact of socioeconomic status on survival outcomes, I plotted histograms for the two subgroups defined earlier:\n",
    "- **First Class (`df_a`)**: Representing passengers with higher socioeconomic status.\n",
    "- **Not First Class (`df_b`)**: Combining passengers from Second and Third Class for a broader comparison.\n",
    "\n",
    "### **Objective**\n",
    "The histograms illustrate the proportion of individuals in each subgroup who survived (`Survived = 1`) or did not survive (`Survived = 0`), normalized for fair comparison.\n",
    "\n",
    "### **Approach**\n",
    "- I created side-by-side bar plots for clarity, using distinct colors to represent each subgroup.\n",
    "- The x-axis represents the survival status (`0 = Did Not Survive`, `1 = Survived`).\n",
    "- The y-axis shows the proportion of individuals in each subgroup for a given survival status.\n",
    "- To ensure consistency, the axis limits are identical across both plots.\n",
    "- Titles, axis labels, and legends are added for clarity and interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "id": "e4pHpxGO1yqM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9379714d32dd31c294222d64ca29e647",
     "grade": true,
     "grade_id": "cell-83a9e33c859463e5",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Define Subgroups Based on Socioeconomic Class ---\n",
    "# First Class (higher socioeconomic status) and Not First Class (combining Second and Third Class)\n",
    "df_a = df_cleaned[df_cleaned['Pclass'] == 1]\n",
    "df_b = df_cleaned[df_cleaned['Pclass'] != 1]\n",
    "\n",
    "# --- Calculate Proportions for Each Subgroup ---\n",
    "# Normalize survival counts to calculate proportions for better comparability.\n",
    "proportions_a = df_a['Survived'].value_counts(normalize=True).sort_index()\n",
    "proportions_b = df_b['Survived'].value_counts(normalize=True).sort_index()\n",
    "\n",
    "# --- Create Bar Plots for Subgroups ---\n",
    "# Setting up side-by-side bar plots for survival proportions of the two subgroups\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "\n",
    "# --- Subgroup A: First Class ---\n",
    "axes[0].bar(\n",
    "    proportions_a.index, \n",
    "    proportions_a.values, \n",
    "    color='green', \n",
    "    alpha=0.7, \n",
    "    label='First Class'\n",
    ")\n",
    "axes[0].set_title('Survival Distribution for First Class', fontsize=14)\n",
    "axes[0].set_xlabel('Survived (0 = Did Not Survive, 1 = Survived)', fontsize=12)\n",
    "axes[0].set_ylabel('Proportion', fontsize=12)\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels(['0\\nDid Not Survive', '1\\nSurvived'])\n",
    "axes[0].legend()\n",
    "\n",
    "# --- Subgroup B: Not First Class ---\n",
    "axes[1].bar(\n",
    "    proportions_b.index, \n",
    "    proportions_b.values, \n",
    "    color='orange', \n",
    "    alpha=0.7, \n",
    "    label='Not First Class'\n",
    ")\n",
    "axes[1].set_title('Survival Distribution for Not First Class', fontsize=14)\n",
    "axes[1].set_xlabel('Survived (0 = Did Not Survive, 1 = Survived)', fontsize=12)\n",
    "axes[1].set_xticks([0, 1])\n",
    "axes[1].set_xticklabels(['0\\nDid Not Survive', '1\\nSurvived'])\n",
    "axes[1].legend()\n",
    "\n",
    "# --- Set Consistent Y-Axis Limits ---\n",
    "# Ensure both subplots share the same scale for accurate comparison.\n",
    "axes[0].set_ylim(0, max(proportions_a.max(), proportions_b.max()) + 0.1)\n",
    "\n",
    "# --- Final Adjustments and Plot Display ---\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()          # Display the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "8A7JNq8A1yqM",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4902394fb6f9b7b1b4f1a7620be5aafc",
     "grade": true,
     "grade_id": "cell-99474d3674e9ddc6",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## **Insights from Survival Distributions by Socioeconomic Class**\n",
    "\n",
    "### **1. Survival Distribution for First Class vs. Not First Class**\n",
    "The histograms highlight significant disparities in survival outcomes based on the sensitive feature `Pclass`:\n",
    "\n",
    "- **First Class**:\n",
    "  - A much larger proportion of passengers in First Class survived (`1`), as indicated by the taller green bar at `1`.\n",
    "  - The proportion of First Class passengers who did not survive (`0`) is significantly smaller, reflected by the shorter green bar at `0`.\n",
    "\n",
    "- **Not First Class**:\n",
    "  - In contrast, passengers in the combined Second and Third Class subgroups experienced much higher non-survival rates, as shown by the taller yellow bar at `0`.\n",
    "  - The proportion of survivors in this group is much smaller, represented by the shorter yellow bar at `1`.\n",
    "\n",
    "### **2. Observations and Analysis**\n",
    "- **Correlation Between `Pclass` and Survival**:\n",
    "  - The survival rates are clearly higher for passengers in First Class compared to those in Not First Class. This indicates a strong correlation between the variable of interest (`Survived`) and the sensitive feature `Pclass`.\n",
    "  \n",
    "- **Historical Context**:\n",
    "  - These disparities align with historical accounts of the Titanic disaster. First Class passengers likely had quicker and easier access to lifeboats due to their privileged status, while Second and Third Class passengers faced greater barriers during evacuation.\n",
    "  - This reflects a broader social class disparity of the time, where socioeconomic status heavily influenced survival odds in emergencies.\n",
    "\n",
    "### **Conclusion**\n",
    "The sensitive feature `Pclass` significantly impacts survival outcomes. The analysis underscores how social hierarchies and access to resources shaped the survival patterns during the Titanic disaster. These findings are not only relevant for understanding historical events but also demonstrate how data analysis can reveal critical social dynamics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "nh2yQ1JN1yqN",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c046cb85e0bc08657b360cbb9d065a0b",
     "grade": false,
     "grade_id": "cell-0101107d18b96ba2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Fairness and Bias in the Dataset**\n",
    "\n",
    "To evaluate fairness and potential bias in the Titanic dataset, I will develop a logistic regression model to predict survival outcomes (`Survived`) based on the available features. Logistic regression is particularly suitable for this task as it produces binary outputs, making it ideal for classification problems like this.\n",
    "\n",
    "### **Preprocessing for Logistic Regression**\n",
    "To prepare the data for modeling, I need to ensure all features are in a numerical format, as the `sklearn` implementation of logistic regression requires numerical inputs. The dataset includes categorical variables, such as `Sex` and `Embarked`, which cannot be directly used in the model. To address this, I will use **one-hot encoding**, a common technique for converting categorical data into numerical representations.\n",
    "\n",
    "### **Steps in Preprocessing**\n",
    "1. **Identify Categorical Features**:\n",
    "   - Features like `Sex` and `Embarked` need to be converted into numerical form.\n",
    "   \n",
    "2. **Apply One-Hot Encoding**:\n",
    "   - Each category in the categorical features will be represented as a binary column, ensuring no ordinal relationships are implied between categories.\n",
    "   \n",
    "3. **Ensure Consistency**:\n",
    "   - Verify that all features are in a format compatible with the logistic regression model.\n",
    "   - Split the data into training and testing sets for model evaluation.\n",
    "\n",
    "This preprocessing step ensures that the dataset is ready for modeling and that the logistic regression model can handle the data effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eVqdKoI-1yqN",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04915aa47dcd1cfc2a5d0a582a924d20",
     "grade": false,
     "grade_id": "cell-fc7e38607fd6f1f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Extracting the Target Variable**\n",
    "\n",
    "To build a machine learning model, I started by isolating the target variable (`Survived`) into its own DataFrame. This step is essential to clearly separate the features (input variables) from the target (output variable), aligning with best practices in model training and evaluation.\n",
    "\n",
    "### **Why This Step?**\n",
    "- The target variable (`Survived`) will be used by the logistic regression model to learn patterns and make predictions.\n",
    "- Separating it into its own DataFrame (`Y`) ensures clarity and simplifies the data pipeline.\n",
    "\n",
    "Below is the code I used to extract the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "id": "VqUicv3Q1yqO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "681a818bfd9243747bec388c76b82810",
     "grade": false,
     "grade_id": "cell-20fa0ca8b24be477",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived\n",
      "0         0\n",
      "1         1\n",
      "2         1\n",
      "3         1\n",
      "4         0\n"
     ]
    }
   ],
   "source": [
    "# --- Extract the Target Variable ---\n",
    "# Isolate the 'Survived' column into a new DataFrame 'Y'\n",
    "# This represents the target variable for the logistic regression model.\n",
    "Y = df_cleaned[['Survived']]\n",
    "\n",
    "# --- Display the First Few Rows of the Target Variable ---\n",
    "# Verify that the target variable has been correctly extracted\n",
    "print(Y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yAxxScmG1yqP",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d793213d313468763bfafee60a5839c4",
     "grade": false,
     "grade_id": "cell-8587895ae41a257f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Setting Up the Features DataFrame**\n",
    "\n",
    "After isolating the target variable (`Y`), the next step is to prepare the features dataset, which includes all the remaining columns except the target. This new DataFrame, `X`, represents the input data that the logistic regression model will use to predict survival outcomes.\n",
    "\n",
    "### **Why This Step?**\n",
    "- Separating features (`X`) from the target (`Y`) ensures a clean data pipeline and aligns with machine learning best practices.\n",
    "- It allows for further preprocessing and transformation of features without affecting the target variable.\n",
    "\n",
    "Below is the code I used to set up the features dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "id": "58R7BDGG1yqP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0b05ea2cd776cf753771e716eec79f3",
     "grade": false,
     "grade_id": "cell-42475005b8da1aa4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0       3    male  22.0      1      0   7.2500        S\n",
      "1       1  female  38.0      1      0  71.2833        C\n",
      "2       3  female  26.0      0      0   7.9250        S\n",
      "3       1  female  35.0      1      0  53.1000        S\n",
      "4       3    male  35.0      0      0   8.0500        S\n"
     ]
    }
   ],
   "source": [
    "# --- Extract Features into 'X' ---\n",
    "# Create a DataFrame 'X' containing all columns except the target column 'Survived'.\n",
    "X = df_cleaned.drop(columns=['Survived'])\n",
    "\n",
    "# --- Verify the Features DataFrame ---\n",
    "# Display the first few rows of the features DataFrame to ensure correctness.\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "52wJ-NZ51yqP",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cde05da30ae69b97b439f051d9caabb4",
     "grade": false,
     "grade_id": "cell-4b8bcb608ae72bc4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Selecting Relevant Features**\n",
    "\n",
    "To ensure that the logistic regression model performs effectively, I carefully selected the features most relevant to predicting survival outcomes (`Survived`). By focusing on these columns, I aim to reduce noise in the dataset while retaining variables with significant predictive power.\n",
    "\n",
    "### **Features Selected**\n",
    "The features I retained in `X` are:\n",
    "- **Pclass**: Socioeconomic class, a key factor influencing survival.\n",
    "- **Sex**: Gender, a sensitive feature historically associated with survival disparities.\n",
    "- **Age**: Passenger age, potentially affecting survival priorities.\n",
    "- **SibSp**: Number of siblings or spouses aboard, indicating family connections.\n",
    "- **Parch**: Number of parents or children aboard, reflecting family presence.\n",
    "- **Fare**: Ticket fare, indirectly linked to socioeconomic status.\n",
    "- **Embarked**: Port of embarkation, which may provide geographical or cultural context.\n",
    "\n",
    "This selection is based on a combination of domain knowledge and data insights derived during the exploration phase.\n",
    "\n",
    "### **Code Implementation**\n",
    "Below is the code I used to retain only the selected columns in `X`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "id": "XMFXsmAw1yqQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3ba8130bf4651e37bcef61a714a5ceb",
     "grade": true,
     "grade_id": "cell-47a97f9a59a2347d",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0       3    male  22.0      1      0   7.2500        S\n",
      "1       1  female  38.0      1      0  71.2833        C\n",
      "2       3  female  26.0      0      0   7.9250        S\n",
      "3       1  female  35.0      1      0  53.1000        S\n",
      "4       3    male  35.0      0      0   8.0500        S\n"
     ]
    }
   ],
   "source": [
    "# --- Define Relevant Features ---\n",
    "# Retain only the columns deemed necessary for analysis and modeling.\n",
    "cols_retain = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "\n",
    "# --- Filter Features in 'X' ---\n",
    "# Update the features DataFrame to include only the selected columns.\n",
    "X = X[cols_retain]\n",
    "\n",
    "# --- Verify the Updated Features DataFrame ---\n",
    "# Display the first few rows to ensure that only the relevant columns are retained.\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "08t8kLNh1yqQ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "430bd9a4988031db9cc202ee1e3a21df",
     "grade": false,
     "grade_id": "cell-f0e29759c74524ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Examining Column Types**\n",
    "\n",
    "Before building the logistic regression model, it is essential to ensure that all data in the features DataFrame (`X`) is numerical. Logistic regression in `sklearn` requires numerical input, so any categorical variables need to be converted into numerical formats.\n",
    "\n",
    "### **Why Examine Column Types?**\n",
    "- **Identify Categorical Variables**: Some columns, such as `Sex` or `Embarked`, may be non-numerical and require preprocessing.\n",
    "- **Ensure Compatibility**: Verifying data types ensures that all features are suitable for use in the logistic regression model.\n",
    "\n",
    "Below is the code to examine the data types of columns in `X`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WodTHVVd1yqR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64fe12ebfc10eb11a5969625051db470",
     "grade": false,
     "grade_id": "cell-b696a2c36afd0ea2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass        int64\n",
      "Sex          object\n",
      "Age         float64\n",
      "SibSp         int64\n",
      "Parch         int64\n",
      "Fare        float64\n",
      "Embarked     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- Examine Column Data Types ---\n",
    "# Display the data types of each column in the features DataFrame\n",
    "print(X.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "X-cRVK7H1yqR",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73f22e4eb924fef40f36a8a06df9dd6a",
     "grade": false,
     "grade_id": "cell-6dd9b6e50e56f508",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Preprocessing Features for Logistic Regression**\n",
    "\n",
    "To prepare the features dataset (`X`) for logistic regression, I performed the following steps:\n",
    "1. **Separated Numerical and Categorical Features**:\n",
    "   - Identified numerical columns that require normalization and categorical columns that need encoding.\n",
    "2. **Applied One-Hot Encoding**:\n",
    "   - Transformed categorical features into numerical values using one-hot encoding to ensure compatibility with the model.\n",
    "3. **Normalized Numerical Features**:\n",
    "   - Used a standard scaler to normalize numerical features, ensuring that they have comparable scales, which is crucial for models like logistic regression.\n",
    "4. **Combined Preprocessed Features**:\n",
    "   - Merged the processed numerical and categorical features into a single dataset.\n",
    "\n",
    "This preprocessing pipeline ensures that the features dataset is fully numerical and well-prepared for logistic regression.\n",
    "\n",
    "### **Code Implementation**\n",
    "Below is the code I used to preprocess the features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "id": "FMiEcLmQ1yqR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ab2534c479a3fcffef408009b7f0cb2",
     "grade": true,
     "grade_id": "cell-de2621bfb172db96",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass       Age     SibSp     Parch      Fare  Sex_female  Sex_male  \\\n",
      "0  0.908600 -0.527669  0.522511 -0.506787 -0.516380         0.0       1.0   \n",
      "1 -1.482983  0.577094  0.522511 -0.506787  0.694046         1.0       0.0   \n",
      "2  0.908600 -0.251478 -0.552714 -0.506787 -0.503620         1.0       0.0   \n",
      "3 -1.482983  0.369951  0.522511 -0.506787  0.350326         1.0       0.0   \n",
      "4  0.908600  0.369951 -0.552714 -0.506787 -0.501257         0.0       1.0   \n",
      "\n",
      "   Embarked_C  Embarked_Q  Embarked_S  \n",
      "0         0.0         0.0         1.0  \n",
      "1         1.0         0.0         0.0  \n",
      "2         0.0         0.0         1.0  \n",
      "3         0.0         0.0         1.0  \n",
      "4         0.0         0.0         1.0  \n"
     ]
    }
   ],
   "source": [
    "# --- Import Necessary Modules ---\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# --- Define Features and Target Variable ---\n",
    "# The target variable (Y) and the features (X)\n",
    "Y = df_cleaned['Survived']  \n",
    "X = df_cleaned.drop(columns=['Survived']) \n",
    "\n",
    "# --- Separate Numerical and Categorical Features ---\n",
    "# Define categorical and numerical columns for preprocessing\n",
    "categorical_cols = ['Sex', 'Embarked']\n",
    "numerical_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "# --- Define Preprocessing Transformers ---\n",
    "# Categorical: One-hot encode the categorical features\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Numerical: Standardize numerical features for better model performance\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# --- Create Preprocessing Pipeline ---\n",
    "# Combine numerical and categorical preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),  # Numerical features\n",
    "        ('cat', categorical_transformer, categorical_cols)  # Categorical features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Preprocess the Features ---\n",
    "# Fit and transform the features using the preprocessing pipeline\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# --- Convert Preprocessed Data to DataFrame ---\n",
    "# Extract feature names for encoded categorical columns\n",
    "encoded_categorical_cols = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Combine numerical and encoded categorical column names\n",
    "all_feature_names = numerical_cols + list(encoded_categorical_cols)\n",
    "\n",
    "# Create a DataFrame for the preprocessed data\n",
    "X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=all_feature_names)\n",
    "\n",
    "# --- Highlight Sensitive Features ---\n",
    "# Sensitive features identified for fairness analysis\n",
    "sensitive_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', \n",
    "                      'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "\n",
    "# --- Display Preprocessed Data ---\n",
    "# Preview the first few rows of the preprocessed dataset\n",
    "print(X_preprocessed_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hWYXthRN1yqT",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a07d8c496379c4534c9de0f03bba670",
     "grade": false,
     "grade_id": "cell-4e6337d1c7743414",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Setting Up the Model Pipeline**\n",
    "\n",
    "To build the logistic regression model, I constructed a pipeline that integrates preprocessing and model training into a single, streamlined workflow. This approach ensures consistency and efficiency, especially when dealing with mixed data types.\n",
    "\n",
    "### **Steps in Setting Up the Pipeline**\n",
    "1. **Preprocessor**:\n",
    "   - **Numerical Features**: Standardized using `StandardScaler` to normalize the scale of features like age and fare.\n",
    "   - **Categorical Features**: Encoded using `OneHotEncoder` to transform non-numerical data into a format suitable for the logistic regression model.\n",
    "\n",
    "2. **Model**:\n",
    "   - A logistic regression classifier was chosen to predict survival outcomes.\n",
    "   - To ensure model convergence during training, I increased the maximum number of iterations (`max_iter`) to 1000.\n",
    "\n",
    "3. **Pipeline**:\n",
    "   - The preprocessing steps and logistic regression model were combined into a single pipeline for seamless data handling and model training.\n",
    "\n",
    "### **Code Implementation**\n",
    "Below is the code I used to set up the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "id": "_ecpohDU1yqT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac348c9a0d94511ec6cb3b50ec88ab14",
     "grade": true,
     "grade_id": "cell-49c6d3a04670e438",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x0000014F1E960E50>),\n",
      "                                                 ('cat', OneHotEncoder(),\n",
      "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x0000014F1E939190>)])),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n"
     ]
    }
   ],
   "source": [
    "# --- Import Necessary Libraries ---\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "# --- Define Feature Selectors ---\n",
    "# Automatically select categorical and numerical features\n",
    "categorical_features = selector(dtype_include='object')\n",
    "numerical_features = selector(dtype_include='number')\n",
    "\n",
    "# --- Set Up Preprocessor ---\n",
    "# Combine preprocessing for numerical and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),  # Standardize numerical features\n",
    "        ('cat', OneHotEncoder(), categorical_features)  # One-hot encode categorical features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Define the Model Pipeline ---\n",
    "# Integrate preprocessing and logistic regression into a single pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Preprocessing step\n",
    "    ('classifier', LogisticRegression(max_iter=1000))  # Logistic regression with increased max iterations\n",
    "])\n",
    "\n",
    "# --- Display the Model Pipeline ---\n",
    "# Print the pipeline to verify the structure\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "CvFxidXx1yqU",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58346e7f0e368a0f54aa5db9917d64b8",
     "grade": false,
     "grade_id": "cell-eb81c8126be6d5e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Splitting the Dataset**\n",
    "\n",
    "To train and evaluate the logistic regression model, I split the dataset into training and testing subsets. This step ensures that the model is trained on one portion of the data while being tested on an unseen portion to assess its performance.\n",
    "\n",
    "### **Splitting Strategy**\n",
    "- **Training Set (`X_train`, `Y_train`)**:\n",
    "  - Comprises 75% of the dataset, used to train the model and learn patterns in the data.\n",
    "- **Test Set (`X_test`, `Y_test`)**:\n",
    "  - Comprises 25% of the dataset, used to evaluate the model's performance on unseen data.\n",
    "- **Random State**:\n",
    "  - A fixed random state (`42`) was set to ensure reproducibility of the split.\n",
    "\n",
    "This train-test split balances the need for training data with the importance of having enough test data to evaluate the model's generalization.\n",
    "\n",
    "### **Code Implementation**\n",
    "Below is the code I used to split the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "id": "0uDUKdrx1yqU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c6d64338ed103b520e6aaa6f8af3e55",
     "grade": true,
     "grade_id": "cell-5d3b4432548625fa",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (534, 10)\n",
      "X_test shape: (178, 10)\n",
      "Y_train shape: (534,)\n",
      "Y_test shape: (178,)\n"
     ]
    }
   ],
   "source": [
    "# --- Import Train-Test Split Module ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Split Dataset into Train and Test Sets ---\n",
    "# The features (X_preprocessed_df) and target (Y) are split into training and testing subsets.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_preprocessed_df,  # Preprocessed features\n",
    "    Y,                  # Target variable\n",
    "    test_size=0.25,     # 25% of the data for testing\n",
    "    random_state=42     # Fixed random state for reproducibility\n",
    ")\n",
    "\n",
    "# --- Verify the Shapes of the Splits ---\n",
    "# Print the shapes of the training and testing datasets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Y_train shape: {Y_train.shape}\")\n",
    "print(f\"Y_test shape: {Y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "sbkv-ODH1yqV",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c53cd998ae0744f1b11a96860d0c23e",
     "grade": false,
     "grade_id": "cell-bba9505f8fc2af6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000014F1E960E50&gt;),\n",
       "                                                 (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000014F1E939190&gt;)])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000014F1E960E50&gt;),\n",
       "                                                 (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000014F1E939190&gt;)])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(max_iter=1000))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000014F1E960E50&gt;),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000014F1E939190&gt;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">num</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000014F1E960E50&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000014F1E939190&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x0000014F1E960E50>),\n",
       "                                                 ('cat', OneHotEncoder(),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x0000014F1E939190>)])),\n",
       "                ('classifier', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we run the logistic regression we have set up\n",
    "# Just run this cell\n",
    "\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "oaqd49t_1yqV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e095e047539d246a5de01a5daa886ae",
     "grade": false,
     "grade_id": "cell-c78a74d1017bb507",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Evaluating the Logistic Regression Model**\n",
    "\n",
    "After training the logistic regression model, the next step is to evaluate its performance on the test dataset (`X_test`, `Y_test`). This involves making predictions and calculating key performance metrics to assess the model's accuracy and effectiveness.\n",
    "\n",
    "### **Steps in Evaluation**\n",
    "1. **Make Predictions**:\n",
    "   - Used the trained model to predict survival outcomes (`Y_pred`) on the test dataset (`X_test`).\n",
    "   \n",
    "2. **Calculate Accuracy**:\n",
    "   - Measured the proportion of correctly predicted outcomes as the overall accuracy of the model.\n",
    "\n",
    "3. **Generate Classification Report**:\n",
    "   - Evaluated additional metrics such as precision, recall, and F1 score for a more comprehensive understanding of the model's performance.\n",
    "\n",
    "4. **Confusion Matrix**:\n",
    "   - Displayed the confusion matrix to examine the distribution of true positives, true negatives, false positives, and false negatives.\n",
    "\n",
    "### **Code Implementation**\n",
    "Below is the code I used to evaluate the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "id": "zl2YOlw11yqW",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06898ea0ff6e15056a608a2fd16bd0e3",
     "grade": false,
     "grade_id": "cell-1761bee9d7c76c2f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7809\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.81        99\n",
      "           1       0.79      0.68      0.73        79\n",
      "\n",
      "    accuracy                           0.78       178\n",
      "   macro avg       0.78      0.77      0.77       178\n",
      "weighted avg       0.78      0.78      0.78       178\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[85 14]\n",
      " [25 54]]\n"
     ]
    }
   ],
   "source": [
    "# --- Import Performance Metrics ---\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# --- Make Predictions on the Test Set ---\n",
    "# Use the trained model to predict survival outcomes for the test dataset\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# --- Calculate Accuracy ---\n",
    "# Compute the accuracy of the model on the test dataset\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")  # Display accuracy to 4 decimal places\n",
    "\n",
    "# --- Generate Classification Report ---\n",
    "# Print precision, recall, F1 score, and support for each class\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "# --- Display Confusion Matrix ---\n",
    "# Show the confusion matrix to understand prediction distribution\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "lVuXt4Tq1yqX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "530e00a137fcc2cacc7f4b91320c6738",
     "grade": false,
     "grade_id": "cell-da8005c9792de3b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Fairness Metrics**\n",
    "\n",
    "To evaluate the fairness of the logistic regression classifier, I first converted the predicted outcomes (`Y_pred`) into a DataFrame. This allows for seamless integration with the test set (`Y_test`) and simplifies subsequent analysis of fairness metrics.\n",
    "\n",
    "### **Why Convert `Y_pred` into a DataFrame?**\n",
    "- **Alignment with Test Set**: Using the same index as `Y_test` ensures that predictions can be directly compared to the true labels and any associated features (e.g., sensitive attributes).\n",
    "- **Ease of Analysis**: DataFrame operations make it straightforward to compute fairness metrics and visualize results.\n",
    "- **Preparation for Advanced Metrics**: Many fairness metrics require predictions and true labels to be structured together for group-wise analysis.\n",
    "\n",
    "### **Code Implementation**\n",
    "Below is the code I used to convert `Y_pred` into a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e8aWh7VB1yqX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b7283120873f1d00c2247a089e92f8e",
     "grade": false,
     "grade_id": "cell-00651bce84e54b3f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Predicted\n",
      "641          1\n",
      "496          1\n",
      "262          0\n",
      "311          1\n",
      "551          0\n"
     ]
    }
   ],
   "source": [
    "# --- Convert Predictions to DataFrame ---\n",
    "# Convert Y_pred (predicted labels) into a DataFrame for easier analysis\n",
    "# Ensure the index matches Y_test for alignment\n",
    "Y_pred = pd.DataFrame(Y_pred, index=Y_test.index, columns=['Predicted'])\n",
    "\n",
    "# --- Verify the Conversion ---\n",
    "# Display the first few rows to ensure correctness\n",
    "print(Y_pred.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "SomD0wB5du4-",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79742f8f8cd65f787fa2590cfbbd59b7",
     "grade": false,
     "grade_id": "cell-b1ee5297b337d03e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Extracting Sensitive Features for Fairness Analysis**\n",
    "\n",
    "To evaluate the fairness of the logistic regression classifier, I extracted the sensitive features into a new DataFrame, `A`. These features will allow me to analyze group-wise performance and assess whether the model treats all groups equitably.\n",
    "\n",
    "### **Why Extract Sensitive Features?**\n",
    "- **Group-wise Analysis**: Sensitive features, such as gender or class, are critical for calculating fairness metrics and identifying potential biases.\n",
    "- **Test Set Alignment**: Extracting these features from the test set ensures that fairness metrics reflect the model's real-world performance on unseen data.\n",
    "- **Preparation for Fairness Metrics**: This step sets the foundation for assessing metrics like accuracy parity, equalized odds, or disparate impact.\n",
    "\n",
    "Below is the code for extracting the sensitive features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yMbJ7mBY1yqX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f8f40b62854c39be8cb01ea66e244b0",
     "grade": false,
     "grade_id": "cell-0f174b417232da98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --- Import Required Package ---\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# --- Extract Sensitive Features ---\n",
    "# Sensitive features are extracted from X_test for fairness analysis\n",
    "# This step is crucial for group-wise evaluation of model predictions\n",
    "# Code is pre-prepared; just run the cell to perform this extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "id": "qw7fsm6V1yqY",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a3070993317661dd4bbec341c3f4149",
     "grade": true,
     "grade_id": "cell-4fbae6c5db541d85",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Pclass       Age     SibSp     Parch      Fare  Sex_female  Sex_male  \\\n",
      "506 -1.482983 -0.389573 -0.552714 -0.506787  0.656556         1.0       0.0   \n",
      "394 -1.482983  1.681856  0.522511 -0.506787  0.826054         1.0       0.0   \n",
      "210 -1.482983  1.543761  0.522511  0.664747  0.852202         0.0       1.0   \n",
      "247 -1.482983 -0.803859  1.597735  1.836282  4.306266         1.0       0.0   \n",
      "437 -0.287191 -0.182430 -0.552714 -0.506787 -0.161947         0.0       1.0   \n",
      "\n",
      "     Embarked_C  Embarked_Q  Embarked_S  \n",
      "506         1.0         0.0         0.0  \n",
      "394         1.0         0.0         0.0  \n",
      "210         0.0         0.0         1.0  \n",
      "247         1.0         0.0         0.0  \n",
      "437         0.0         0.0         1.0  \n",
      "Pclass\n",
      " 0.908600    82\n",
      "-1.482983    50\n",
      "-0.287191    46\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Define Sensitive Features ---\n",
    "# These features are used for fairness analysis to examine group-wise performance\n",
    "sensitive_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female', 'Sex_male',\n",
    "                      'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "\n",
    "# --- Extract Sensitive Features ---\n",
    "# Filter the test set to include only the defined sensitive features\n",
    "A = X_test[sensitive_features]\n",
    "\n",
    "# --- Verify the Extracted Features ---\n",
    "# Display the first few rows of the extracted sensitive features\n",
    "print(A.head())\n",
    "\n",
    "# --- Verify Group Sizes for a Key Sensitive Feature ---\n",
    "# Print value counts for the 'Pclass' feature to check subgroup distribution\n",
    "print(X_test['Pclass'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8K3zhMyc1yqZ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97449fd0e5d1f8b84df5da72dfca59fa",
     "grade": false,
     "grade_id": "cell-01b2680145e08a32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Fairness Metrics: TPR, FPR, and Positive Label Rate**\n",
    "\n",
    "To evaluate fairness in the classifier, I implemented three functions to compute key metrics for specific subgroups defined by a sensitive feature. These metrics help identify whether the model's performance differs across groups, ensuring equitable treatment.\n",
    "\n",
    "### **1. True Positive Rate (TPR)**\n",
    "The `tpr_metric` function calculates the proportion of actual positives (`1`) that are correctly predicted as positive:\n",
    "\\[\n",
    "TPR = \\frac{TP}{TP + FN}\n",
    "\\]\n",
    "- **Parameters**:\n",
    "  - `Y_true`: True labels (ground truth).\n",
    "  - `Y_pred`: Predicted labels from the model.\n",
    "  - `x`: Features dataset corresponding to `Y_true`.\n",
    "  - `s_feature`: Sensitive feature to define the subgroup.\n",
    "  - `s_value`: Specific value of the sensitive feature for subgroup evaluation.\n",
    "- **Purpose**: Measures the model's ability to correctly identify positive cases for the subgroup.\n",
    "\n",
    "### **2. False Positive Rate (FPR)**\n",
    "The `fpr_metric` function calculates the proportion of actual negatives (`0`) that are incorrectly predicted as positive:\n",
    "\\[\n",
    "FPR = \\frac{FP}{FP + TN}\n",
    "\\]\n",
    "- **Parameters**:\n",
    "  - Same as `tpr_metric`.\n",
    "- **Purpose**: Assesses how often the model falsely predicts positive labels for the subgroup.\n",
    "\n",
    "### **3. Positive Label Rate**\n",
    "The `poslabel_metric` function computes the rate of positive predictions (`1`) for the subgroup:\n",
    "\\[\n",
    "P[y_{pred} = 1 | s_{feature} = s_{value}]\n",
    "\\]\n",
    "- **Parameters**:\n",
    "  - `Y_pred`: Predicted labels from the model.\n",
    "  - `x`: Features dataset corresponding to `Y_pred`.\n",
    "  - `s_feature`: Sensitive feature to define the subgroup.\n",
    "  - `s_value`: Specific value of the sensitive feature for subgroup evaluation.\n",
    "- **Purpose**: Measures the likelihood of assigning a positive label to the subgroup, regardless of ground truth.\n",
    "\n",
    "### **Why These Metrics Matter**\n",
    "- **TPR**: Ensures the model effectively identifies positives across groups.\n",
    "- **FPR**: Highlights potential biases where the model unfairly predicts positives for a specific group.\n",
    "- **Positive Label Rate**: Reflects whether the model disproportionately assigns positive labels to certain groups.\n",
    "\n",
    "### **Code Implementation**\n",
    "Below are the implementations for the three metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "id": "J8ECyfW51yqa",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6a60ad8152dc59569c9a61e63897cb6",
     "grade": true,
     "grade_id": "cell-bb7712e2586f909d",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tpr_metric(Y_true, Y_pred, x, s_feature, s_value):\n",
    "    '''\n",
    "    Calculates the True Positive Rate (TPR) for a specific subgroup.\n",
    "    '''\n",
    "    tpr = 0\n",
    "    if isinstance(Y_pred, pd.DataFrame):\n",
    "        Y_pred = Y_pred.iloc[:, 0]\n",
    "    if isinstance(Y_true, pd.DataFrame):\n",
    "        Y_true = Y_true.iloc[:, 0]\n",
    "    Y_pred = Y_pred.reindex(x.index)\n",
    "    Y_true = Y_true.reindex(x.index)\n",
    "    subgroup_indices = x[s_feature] == s_value\n",
    "    y_true_subgroup = Y_true[subgroup_indices]\n",
    "    y_pred_subgroup = Y_pred[subgroup_indices]\n",
    "\n",
    "    tp = ((y_true_subgroup == 1) & (y_pred_subgroup == 1)).sum()  # True Positives\n",
    "    fn = ((y_true_subgroup == 1) & (y_pred_subgroup == 0)).sum()  # False Negatives\n",
    "\n",
    "    if (tp + fn) > 0:\n",
    "        tpr = tp / (tp + fn)\n",
    "    return tpr\n",
    "\n",
    "def fpr_metric(Y_true, Y_pred, x, s_feature, s_value):\n",
    "    '''\n",
    "    Calculates the False Positive Rate (FPR) for a specific subgroup.\n",
    "    '''\n",
    "    fpr = 0\n",
    "    if isinstance(Y_pred, pd.DataFrame):\n",
    "        Y_pred = Y_pred.iloc[:, 0]\n",
    "    if isinstance(Y_true, pd.DataFrame):\n",
    "        Y_true = Y_true.iloc[:, 0]\n",
    "    Y_pred = Y_pred.reindex(x.index)\n",
    "    Y_true = Y_true.reindex(x.index)\n",
    "    subgroup_indices = x[s_feature] == s_value\n",
    "    y_true_subgroup = Y_true[subgroup_indices]\n",
    "    y_pred_subgroup = Y_pred[subgroup_indices]\n",
    "\n",
    "    fp = ((y_true_subgroup == 0) & (y_pred_subgroup == 1)).sum()  # False Positives\n",
    "    tn = ((y_true_subgroup == 0) & (y_pred_subgroup == 0)).sum()  # True Negatives\n",
    "\n",
    "    if (fp + tn) > 0:\n",
    "        fpr = fp / (fp + tn)\n",
    "    return fpr\n",
    "\n",
    "def poslabel_metric(Y_pred, x, s_feature, s_value):\n",
    "    '''\n",
    "    Calculates the Positive Label Rate for a specific subgroup.\n",
    "    '''\n",
    "    poslabel = 0\n",
    "    if isinstance(Y_pred, pd.DataFrame):\n",
    "        Y_pred = Y_pred.iloc[:, 0]\n",
    "    Y_pred = Y_pred.reindex(x.index)\n",
    "    subgroup_indices = x[s_feature] == s_value\n",
    "\n",
    "    y_pred_subgroup = Y_pred[subgroup_indices]\n",
    "    positive_labels = (y_pred_subgroup == 1).sum()\n",
    "    total_individuals = subgroup_indices.sum()\n",
    "\n",
    "    if total_individuals > 0:\n",
    "        poslabel = positive_labels / total_individuals\n",
    "    return poslabel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0WiVMN6z1yqb",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "adb4f26e9194c1a11145c093e784a81c",
     "grade": false,
     "grade_id": "cell-bbd72a52a13f4794",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Fairness Metrics: Measuring Parity Differences**\n",
    "\n",
    "Fairness metrics help evaluate whether a model treats different subgroups equitably. Here, I focused on three key definitions of fairness differences:\n",
    "\n",
    "1. **Demographic Parity Difference**:\n",
    "   - Measures the gap in the rate of positive labels between two subgroups.\n",
    "   \\[\n",
    "   \\text{Demographic Parity Difference} = P[Y_{\\text{pred}} = 1 | A = 1] - P[Y_{\\text{pred}} = 1 | A = 0]\n",
    "   \\]\n",
    "\n",
    "2. **Equal Opportunity Difference**:\n",
    "   - Measures the gap in true positive rates (TPR) between two subgroups.\n",
    "   \\[\n",
    "   \\text{Equal Opportunity Difference} = \\text{TPR}(A = 1) - \\text{TPR}(A = 0)\n",
    "   \\]\n",
    "\n",
    "3. **Equalized Odds Difference**:\n",
    "   - Captures differences in both TPR and false positive rates (FPR) between subgroups. The output is a vector:\n",
    "   \\[\n",
    "   \\text{Equalized Odds Difference} = [\\text{TPR Diff}, \\text{FPR Diff}]\n",
    "   \\]\n",
    "\n",
    "---\n",
    "\n",
    "### **Analysis of Fairness Metrics**\n",
    "\n",
    "#### **1. First Sensitive Feature: `Sex_female` vs. `Sex_male`**\n",
    "- **Demographic Parity Difference**:\n",
    "  - This measures whether females and males receive positive labels (e.g., predicted survivors) at similar rates. A significant difference suggests bias in favor of one gender.\n",
    "- **Equal Opportunity Difference**:\n",
    "  - Examines differences in TPR between females and males, indicating whether the model is better at correctly predicting survival for one gender over the other.\n",
    "- **Equalized Odds Difference**:\n",
    "  - Evaluates disparities in both TPR and FPR, revealing whether the model treats males and females fairly in terms of both correctly identifying survivors and avoiding false positives.\n",
    "\n",
    "#### **2. Second Sensitive Feature: `Pclass` (First Class vs. Third Class)**\n",
    "- **Demographic Parity Difference**:\n",
    "  - This metric highlights whether passengers in First Class and Third Class are equally likely to receive positive predictions. Large differences may reflect historical bias favoring First Class passengers.\n",
    "- **Equal Opportunity Difference**:\n",
    "  - Assesses whether the model is equally effective at identifying actual survivors across classes. Disparities here suggest unequal treatment of socioeconomic groups.\n",
    "- **Equalized Odds Difference**:\n",
    "  - Captures gaps in both TPR and FPR, indicating whether the model is fair to all classes in terms of both accurate predictions and avoidance of false positives.\n",
    "\n",
    "#### **3. Age: Young Subgroup (`Age < 30`) vs. Old Subgroup (`Age >= 30`)**\n",
    "- **Demographic Parity Difference**:\n",
    "  - Compares the likelihood of young and old passengers being predicted as survivors. Large differences may indicate age-related bias.\n",
    "- **Equal Opportunity Difference**:\n",
    "  - Measures whether the model is equally effective at identifying true survivors in both age groups.\n",
    "- **Equalized Odds Difference**:\n",
    "  - Evaluates fairness in terms of both TPR and FPR for young and old passengers, identifying disparities in accurate and false predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### **Is the Model Fair?**\n",
    "I assessed fairness by analyzing the magnitude of these metrics:\n",
    "- **Demographic Parity Difference**: Ideally close to zero, indicating no subgroup receives preferential positive predictions.\n",
    "- **Equal Opportunity Difference**: Small values suggest the model is equally effective at identifying true positives across subgroups.\n",
    "- **Equalized Odds Difference**: Minimal disparities in both TPR and FPR indicate that the model treats subgroups equitably in terms of accurate predictions and avoiding false positives.\n",
    "\n",
    "By combining these metrics, I gained a comprehensive understanding of the model’s fairness and can identify areas for improvement. Large differences in any metric suggest the need to revisit the model or data preprocessing to address potential biases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "id": "TPdAfAEY1yqc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccf027394dd4253cbfcf4ec6bea2ac7a",
     "grade": true,
     "grade_id": "cell-35214af1dc698642",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity Difference: 0.05401069518716578\n",
      "Equal Opportunity Difference: -0.02777777777777779\n",
      "Equalized Odds Differences (TPR, FPR): [-0.02777777777777779, 0.2857142857142857]\n"
     ]
    }
   ],
   "source": [
    "# First Sensitive Feature: Sex_female vs Sex_male\n",
    "sensitive_feature1 = 'Sex_female'\n",
    "sensitive_feature2 = 'Sex_male'\n",
    "\n",
    "# --- Demographic Parity Difference ---\n",
    "demographic_parity = poslabel_metric(Y_pred, X_test, sensitive_feature1, 1) - poslabel_metric(Y_pred, X_test, sensitive_feature2, 1)\n",
    "print(\"Demographic Parity Difference:\", demographic_parity)\n",
    "\n",
    "# --- Equal Opportunity Difference ---\n",
    "eq_opp_diff = tpr_metric(Y_test, Y_pred, X_test, sensitive_feature1, 1) - tpr_metric(Y_test, Y_pred, X_test, sensitive_feature2, 1)\n",
    "print(\"Equal Opportunity Difference:\", eq_opp_diff)\n",
    "\n",
    "# --- Equalized Odds Difference ---\n",
    "fpr_diff = fpr_metric(Y_test, Y_pred, X_test, sensitive_feature1, 1) - fpr_metric(Y_test, Y_pred, X_test, sensitive_feature2, 1)\n",
    "print(\"Equalized Odds Differences (TPR, FPR):\", [eq_opp_diff, fpr_diff])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "eR_BiiyHdu4_",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25860304599669687dc93c3571345d7f",
     "grade": true,
     "grade_id": "cell-e8bbab651d3fd641",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "### **Fairness Metrics Analysis**\n",
    "\n",
    "- **Demographic Parity Difference**:  \n",
    "  I calculated the difference in prediction rates between `Sex_female` and `Sex_male`, and it came out to **0.054**. This tells me there’s a small disparity in the likelihood of receiving a positive prediction based on gender, but it’s not overly large.\n",
    "\n",
    "- **Equal Opportunity Difference**:  \n",
    "  The difference in true positive rates (TPR) that I observed was **-0.0278**. This suggests that the model is slightly better at correctly predicting true survivors for one gender over the other, but the small value indicates that it’s mostly fair in this regard.\n",
    "\n",
    "- **Equalized Odds Difference**:  \n",
    "  - **TPR Difference**: **-0.0278**  \n",
    "  - **FPR Difference**: **0.2857**  \n",
    "  While the TPR difference is still small, I noticed a significant disparity in false positive rates (FPR). The model seems more likely to assign false positives to one group over the other, which is an important fairness concern I need to address.\n",
    "\n",
    "### **Conclusion**:\n",
    "From my analysis, while the model seems relatively fair in terms of TPR and demographic parity, the FPR difference of **0.2857** stands out. This suggests that the model may not treat the subgroups equitably when it comes to false predictions, and I want to explore ways to improve fairness in this area.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "id": "Zr5O1YLo1yqc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8a529dfafe13af23d5af34828561ec3",
     "grade": true,
     "grade_id": "cell-bbcd431560d40657",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity Difference: -0.1129374337221633\n",
      "Equal Opportunity Difference: -0.38888888888888884\n",
      "Equalized Odds Differences (TPR, FPR): [-0.38888888888888884, 0.15384615384615385]\n"
     ]
    }
   ],
   "source": [
    "# --- Demographic Parity Difference ---\n",
    "# I created custom bins and labels to group Pclass into categories for fairness analysis.\n",
    "bins = [-np.inf, -0.5, 0.5, np.inf]  # Define ranges for Pclass groups\n",
    "labels = ['Pclass_3', 'Pclass_2', 'Pclass_1']  # Assign meaningful labels to each group\n",
    "X_test['Pclass_group'] = pd.cut(X_test['Pclass'], bins=bins, labels=labels)\n",
    "\n",
    "# Sensitive feature for comparison\n",
    "sensitive_feature = 'Pclass_group'\n",
    "\n",
    "# Calculate Demographic Parity Difference\n",
    "demographic_parity = poslabel_metric(Y_pred, X_test, sensitive_feature, \"Pclass_1\") - poslabel_metric(Y_pred, X_test, sensitive_feature, \"Pclass_2\")\n",
    "print(\"Demographic Parity Difference:\", demographic_parity)\n",
    "\n",
    "# --- Equal Opportunity Difference ---\n",
    "# I calculated the difference in TPR between First Class (Pclass_1) and Second Class (Pclass_2).\n",
    "eq_opp_diff = tpr_metric(Y_test, Y_pred, X_test, sensitive_feature, \"Pclass_1\") - tpr_metric(Y_test, Y_pred, X_test, sensitive_feature, \"Pclass_2\")\n",
    "print(\"Equal Opportunity Difference:\", eq_opp_diff)\n",
    "\n",
    "# --- Equalized Odds Difference ---\n",
    "# I calculated the differences in both TPR and FPR for these subgroups.\n",
    "fpr_diff = fpr_metric(Y_test, Y_pred, X_test, sensitive_feature, \"Pclass_1\") - fpr_metric(Y_test, Y_pred, X_test, sensitive_feature, \"Pclass_2\")\n",
    "print(\"Equalized Odds Differences (TPR, FPR):\", [eq_opp_diff, fpr_diff])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "B1Q6WWciMRDY",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58040e914b8a907d7c6c02373f75e953",
     "grade": true,
     "grade_id": "cell-cc6ddb7d332610c3",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "### **Explanation**\n",
    "\n",
    "I calculated the fairness metrics for `Pclass_1` (First Class) and `Pclass_2` (Second Class), and here’s what I observed:\n",
    "\n",
    "- **Demographic Parity Difference**:  \n",
    "  The difference in prediction rates is **-0.113**, indicating that passengers in `Pclass_2` (Second Class) are slightly more likely to receive positive predictions compared to those in `Pclass_1` (First Class).\n",
    "\n",
    "- **Equal Opportunity Difference**:  \n",
    "  The TPR difference is **-0.3889**, which is significantly larger. This shows that the model is better at correctly identifying true positives for passengers in `Pclass_2` compared to those in `Pclass_1`.\n",
    "\n",
    "- **Equalized Odds Difference**:  \n",
    "  - **TPR Difference**: **-0.3889**  \n",
    "  - **FPR Difference**: **0.1538**  \n",
    "  These values indicate that the model treats the two groups unequally, with noticeable discrepancies in both true positive and false positive rates. The larger disparity in TPR suggests a more pronounced issue in correctly identifying true survivors for `Pclass_1`.\n",
    "\n",
    "### **Conclusion**\n",
    "The significant differences in equal opportunity and TPR suggest a notable disparity in the model’s performance between these groups. This highlights a fairness concern, and I’d like to investigate potential improvements to ensure more equitable treatment across these subgroups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "id": "FHXcBfds1yqc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6b59587a197cd00f2147d95341e18cc",
     "grade": true,
     "grade_id": "cell-c67bc5db359dd147",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity Difference: 0.08426966292134831\n",
      "Equal Opportunity Difference: 0.7647058823529411\n",
      "Equalized Odds Differences (TPR, FPR): [0.7647058823529411, 0.10526315789473684]\n"
     ]
    }
   ],
   "source": [
    "# --- Demographic Parity Difference ---\n",
    "# Create an AgeGroup column to classify passengers as \"young\" or \"old\"\n",
    "young_age_threshold = 30\n",
    "old_age_threshold = 50\n",
    "X_test['AgeGroup'] = [\"young\" if age <= young_age_threshold else \"old\" for age in X_test['Age']]\n",
    "\n",
    "# Calculate Demographic Parity Difference\n",
    "demographic_parity = poslabel_metric(Y_pred, X_test, \"AgeGroup\", \"young\") - poslabel_metric(Y_pred, X_test, \"AgeGroup\", \"old\")\n",
    "print(\"Demographic Parity Difference:\", demographic_parity)\n",
    "\n",
    "# --- Equal Opportunity Difference ---\n",
    "# Calculate the TPR difference between young and old age groups\n",
    "eq_opp_diff = tpr_metric(Y_test, Y_pred, X_test, \"AgeGroup\", \"young\") - tpr_metric(Y_test, Y_pred, X_test, \"AgeGroup\", \"old\")\n",
    "print(\"Equal Opportunity Difference:\", eq_opp_diff)\n",
    "\n",
    "# --- Equalized Odds Difference ---\n",
    "# Calculate differences in both TPR and FPR between young and old age groups\n",
    "fpr_diff = fpr_metric(Y_test, Y_pred, X_test, \"AgeGroup\", \"young\") - fpr_metric(Y_test, Y_pred, X_test, \"AgeGroup\", \"old\")\n",
    "print(\"Equalized Odds Differences (TPR, FPR):\", [eq_opp_diff, fpr_diff])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "G8vP25LUM6Pf",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a2eb3de9a6bf895186a11b8848881304",
     "grade": true,
     "grade_id": "cell-c7acc6950a386d7e",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "### **Explanation**\n",
    "\n",
    "I analyzed the fairness metrics for the `young` (≤30 years old) and `old` (>30 years old) age groups, and here’s what I found:\n",
    "\n",
    "- **Demographic Parity Difference**:  \n",
    "  The difference in prediction rates is **0.0843**, showing a slight disparity in the likelihood of receiving positive predictions between the two age groups.\n",
    "\n",
    "- **Equal Opportunity Difference**:  \n",
    "  The TPR difference is **0.7647**, which is a significant disparity. This indicates that the model is much better at correctly identifying true positives for one group (e.g., `old`) compared to the other (`young`).\n",
    "\n",
    "- **Equalized Odds Difference**:  \n",
    "  - **TPR Difference**: **0.7647**  \n",
    "  - **FPR Difference**: **0.1053**  \n",
    "  These results highlight a substantial gap in the model's ability to treat the groups equitably. The TPR difference suggests that the model favors one group in identifying true positives, while the smaller FPR difference indicates less disparity in false positives.\n",
    "\n",
    "### **Conclusion**\n",
    "The large difference in **equal opportunity (TPR)** suggests that the model may not provide equal opportunity across the age groups, especially in correctly identifying true survivors. This points to a need for further improvements to enhance fairness and ensure the model treats both groups more equitably.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "oiP_EJobdu5A",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a99b454c50f7e9878aee9dce2b0af662",
     "grade": false,
     "grade_id": "cell-691206572ce0abce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **Evaluating Classifier Performance**\n",
    "\n",
    "To assess the overall performance of my classifier, I generated a classification report and calculated the accuracy score. This helps me understand how well the model is performing across various metrics and how fair it is across subgroups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "id": "aEDS68zW1yqh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08f4e16ab12b21a6d67df405e3f03ab3",
     "grade": true,
     "grade_id": "cell-7609f60b9c1cffdd",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.81        99\n",
      "           1       0.79      0.68      0.73        79\n",
      "\n",
      "    accuracy                           0.78       178\n",
      "   macro avg       0.78      0.77      0.77       178\n",
      "weighted avg       0.78      0.78      0.78       178\n",
      "\n",
      "Accuracy: 0.7809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Generate predictions\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "# Accuracy Score\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "pD7WcGlrdu5A",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b7ab354ba0bb18bb37311fa15833712",
     "grade": true,
     "grade_id": "cell-6cf53c984b2ec8b2",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "### **Final Analysis and Observations**\n",
    "\n",
    "I evaluated the classifier’s performance using a classification report, which provided detailed insights into its behavior across multiple metrics:\n",
    "\n",
    "1. **Precision**:  \n",
    "   - The precision score reflects the model's ability to correctly predict positive outcomes (e.g., survival). While the precision is reasonably high, there are minor discrepancies when evaluated across sensitive features, such as gender (`Sex_female` vs. `Sex_male`) and class (`Pclass_1` vs. `Pclass_2`).\n",
    "\n",
    "2. **Recall (Sensitivity/TPR)**:  \n",
    "   - The recall score indicates how well the model identifies actual positive cases. During the fairness analysis, I observed that recall (or TPR) disparities exist between some subgroups, particularly between younger and older age groups and socioeconomic classes. This indicates that the model may perform better for certain groups in recognizing survivors.\n",
    "\n",
    "3. **F1 Score**:  \n",
    "   - The F1 score, balancing precision and recall, showed strong overall performance but highlighted areas where improvements are needed to ensure subgroup equity.\n",
    "\n",
    "4. **Accuracy**:  \n",
    "   - The model achieved a high accuracy score (**{accuracy:.4f}**), which suggests that it performs well overall. However, accuracy alone does not reflect fairness across subgroups, which is why I analyzed additional fairness metrics.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "This project has allowed me to explore the Titanic dataset, preprocess the data, build and evaluate a logistic regression model, and assess fairness metrics across sensitive features. Here are my key takeaways:\n",
    "\n",
    "1. **Model Performance**:  \n",
    "   - The model demonstrates strong overall performance based on accuracy, precision, recall, and F1 score. It effectively predicts survival outcomes for the majority of cases.\n",
    "\n",
    "2. **Fairness Analysis**:  \n",
    "   - While the model performs well overall, fairness metrics revealed disparities in demographic parity, equal opportunity (TPR), and equalized odds (TPR and FPR) between subgroups:\n",
    "     - **Gender**: Minor differences in prediction rates and TPR suggest the model is relatively fair but has room for improvement.\n",
    "     - **Socioeconomic Class**: Larger disparities between First and Second Class passengers indicate potential bias in survival predictions.\n",
    "     - **Age**: Significant differences in recall (TPR) between younger and older passengers highlight the need for further fairness interventions.\n",
    "\n",
    "3. **Opportunities for Improvement**:  \n",
    "   - To address fairness concerns, I would explore advanced preprocessing techniques, such as re-sampling underrepresented groups or applying fairness-aware algorithms during training.\n",
    "   - Implementing post-processing adjustments to predictions could also help balance outcomes across subgroups.\n",
    "\n",
    "---\n",
    "\n",
    "### **Closing Remarks**\n",
    "\n",
    "This project has been an invaluable opportunity for me to apply data science concepts, explore algorithmic fairness, and refine my skills in logistic regression modeling and evaluation. Beyond technical implementation, I’ve gained a deeper understanding of the importance of fairness in machine learning models, particularly when they have real-world implications.\n",
    "\n",
    "I’m excited about the insights gained from this analysis and look forward to leveraging these skills in future data science projects. If you’d like to discuss this project further or have feedback, I’d be happy to hear from you!\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
